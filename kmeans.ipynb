{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HyNGb3TJQH9P"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt #Data Visualization\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('../input/Mall_Customers.csv')\n",
        "\n",
        "#Exploratory Data Analysis\n",
        "#As this is unsupervised learning so Label (Output Column) is unknown\n",
        "\n",
        "dataset.head(10)"
      ],
      "metadata": {
        "id": "LmuDBfiSQqoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#total rows and colums in the dataset\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "BsvSMhQEQsj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "HHMZ6o0rQuQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Missing values computation\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "105sMAYvQv3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Feature sleection for the model\n",
        "#Considering only 2 features (Annual income and Spending Score) and no Label available\n",
        "X= dataset.iloc[:, [3,4]].values"
      ],
      "metadata": {
        "id": "GEIC_zRXQ9q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the Model\n",
        "#KMeans Algorithm to decide the optimum cluster number , KMeans++ using Elbow Mmethod\n",
        "#to figure out K for KMeans, I will use ELBOW Method on KMEANS++ Calculation\n",
        "from sklearn.cluster import KMeans\n",
        "wcss=[]\n",
        "\n",
        "#we always assume the max number of cluster would be 10\n",
        "#you can judge the number of clusters by doing averaging\n",
        "###Static code to get max no of clusters\n",
        "\n",
        "for i in range(1,11):\n",
        "    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n",
        "    kmeans.fit(X)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "    #inertia_ is the formula used to segregate the data points into clusters"
      ],
      "metadata": {
        "id": "Ov8UAjQ-RIYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the ELBOW method to get the optimal value of K\n",
        "plt.plot(range(1,11), wcss)\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('no of clusters')\n",
        "plt.ylabel('wcss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "prfthglrRKFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If you zoom out this curve then you will see that last elbow comes at k=5\n",
        "#no matter what range we select ex- (1,21) also i will see the same behaviour but if we chose higher range it is little difficult to visualize the ELBOW\n",
        "#that is why we usually prefer range (1,11)\n",
        "##Finally we got that k=5\n",
        "\n",
        "#Model Build\n",
        "kmeansmodel = KMeans(n_clusters= 5, init='k-means++', random_state=0)\n",
        "y_kmeans= kmeansmodel.fit_predict(X)\n",
        "\n",
        "#For unsupervised learning we use \"fit_predict()\" wherein for supervised learning we use \"fit_tranform()\"\n",
        "#y_kmeans is the final model . Now how and where we will deploy this model in production is depends on what tool we are using.\n",
        "#This use case is very common and it is used in BFS industry(credit card) and retail for customer segmenattion."
      ],
      "metadata": {
        "id": "VfqSIXP8ROVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing all the clusters\n",
        "\n",
        "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\n",
        "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\n",
        "plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\n",
        "plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\n",
        "plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\n",
        "plt.title('Clusters of customers')\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XtY2ETwhRSEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "tyUFBOi5RZn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}